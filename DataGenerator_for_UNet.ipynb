{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataGenerator_for_UNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMR1G5YrhNhebB6RIN+dRz8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShankarPoudel441/self-Sub-functions/blob/main/DataGenerator_for_UNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "jIbgnHTLMPZh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping"
      ],
      "metadata": {
        "id": "3wqVcTHHy9XM"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jOtKSPcSGDH",
        "outputId": "e149190d-304f-4f0b-bfdd-8b56206139e6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bye4sR8gSJNv",
        "outputId": "7d99c0df-a2c3-45fe-84f2-b47a21090c92"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W=256\n",
        "H=256\n",
        "\n",
        "test_df_path='/content/drive/MyDrive/CBIS-DDSM/Unet_mask/mass/Image_mask_test.csv'\n",
        "train_df_path=\"/content/drive/MyDrive/CBIS-DDSM/Unet_mask/mass/Image_mask_train.csv\"\n",
        "\n",
        "image_mask_test=pd.read_csv(test_df_path)\n",
        "img_mask=cv2.imread(image_mask_test[\"mask_destination\"][0])\n",
        "img_mask.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJVv-6A6SGLU",
        "outputId": "03a525c9-a605-46c3-adc6-c35154eeda12"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4006, 1846, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data(dataframe_path):\n",
        "  df = pd.read_csv(dataframe_path)\n",
        "  print(dataframe_path)\n",
        "  images=df.image_file.values\n",
        "  masks=df.mask_destination.values\n",
        "  # print(images)\n",
        "  # print(masks)\n",
        "\n",
        "  return images, masks"
      ],
      "metadata": {
        "id": "bRDxLZ4RPVOu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(test_df_path,train_df_path):\n",
        "  test_df_path='/content/drive/MyDrive/CBIS-DDSM/Unet_mask/mass/Image_mask_test.csv'\n",
        "  train_df_path=\"/content/drive/MyDrive/CBIS-DDSM/Unet_mask/mass/Image_mask_train.csv\"\n",
        "\n",
        "  train_x, train_y=process_data(train_df_path)\n",
        "  test_x, test_y = process_data(test_df_path)\n",
        "\n",
        "  train_x,val_x=train_test_split(train_x, test_size=0.2, random_state=42)\n",
        "  train_y,val_y=train_test_split(train_y, test_size=0.2, random_state=42)\n",
        "\n",
        "  return (train_x, train_y), (val_x,val_y), (test_x,test_y)\n",
        "\n"
      ],
      "metadata": {
        "id": "_TPZ9stTPVUG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_image(x):\n",
        "  x=cv2.imread(x,cv2.IMREAD_COLOR)\n",
        "  x = cv2.resize(x, (W,H))\n",
        "  x = x/255.0\n",
        "  x = x.astype(np.float32)\n",
        "  return x\n",
        "\n",
        "\n",
        "def read_mask(x):\n",
        "  x = cv2.imread(x,cv2.IMREAD_GRAYSCALE)\n",
        "  # print(x.shape)\n",
        "  x = cv2.resize(x, (W,H))\n",
        "  # print(x.shape)\n",
        "  x = x.astype(np.int32)\n",
        "  return x"
      ],
      "metadata": {
        "id": "3BEEXRFumm4H"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def preprocess(x,y):\n",
        "  def f(x,y):\n",
        "    x= x.decode()\n",
        "    y= y.decode()\n",
        "\n",
        "    image = read_image(x)\n",
        "    mask = read_mask(y)\n",
        "\n",
        "    return image,mask\n",
        "\n",
        "  image, mask = tf.numpy_function(f, (x,y), [tf.float32, tf.int32])\n",
        "\n",
        "  mask = tf.one_hot(mask, 2, dtype=tf.int32)\n",
        "  mask.set_shape([H,W,2])\n",
        "\n",
        "  image.set_shape([H,W,3])\n",
        "  # mask.set_shape([H,W,1])\n",
        "\n",
        "  return image,mask\n",
        "  "
      ],
      "metadata": {
        "id": "lSPSxvtKgodz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tf_dataset(x, y, batch=8):\n",
        "  dataset=tf.data.Dataset.from_tensor_slices((x,y))\n",
        "  dataset = dataset.shuffle(buffer_size=5000)\n",
        "  dataset = dataset.map(preprocess)\n",
        "  dataset = dataset.batch(batch)\n",
        "  dataset = dataset.repeat()\n",
        "  dataset = dataset.prefetch(3)\n",
        "  return dataset "
      ],
      "metadata": {
        "id": "FbKa-uPYhuWk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(train_x,train_y), (val_x,val_y), (test_x,test_y) = load_data(test_df_path,train_df_path)\n",
        "print(f\"Dataset: Train: {len(train_x)} -Valid: {len(val_x)} -Test: {len(test_x)}\")\n",
        "print(f\"Masks: Train: {len(train_y)} -Valid: {len(val_y)} -Test:{len(test_y)}\")\n",
        "\n",
        "# read_mask(train_y[0])\n",
        "dataset= tf_dataset(train_x,train_y,batch=8)\n",
        "for x,y in dataset:\n",
        "  print(x.shape, y.shape)  #8,256,256,3   8,256,256,2//8,256,256,1\n",
        "  break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWAszea0PVYh",
        "outputId": "d7d91052-b8a9-4e0a-cbde-2fae757bda63"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CBIS-DDSM/Unet_mask/mass/Image_mask_train.csv\n",
            "/content/drive/MyDrive/CBIS-DDSM/Unet_mask/mass/Image_mask_test.csv\n",
            "Dataset: Train: 916 -Valid: 230 -Test: 327\n",
            "Masks: Train: 916 -Valid: 230 -Test:327\n",
            "(8, 256, 256, 3) (8, 256, 256, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  \n"
      ],
      "metadata": {
        "id": "MpZOZTLgS8nP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SPuIlM5TgcX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "v6P0X6iIe_qp"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Zo3oNoaPe_v3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "J3Z5GFHBe_0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Zld07scJe_4n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "E3C9JTeqe_9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "g4lqwo1WfACD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qTNolXwCfAGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, Input, BatchNormalization, Activation, MaxPool2D, UpSampling2D, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n"
      ],
      "metadata": {
        "id": "inqMqLh_WhoC"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(inputs, filters, pool = True):\n",
        "  x=Conv2D(filters, 3, padding=\"same\") (inputs)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Activation(\"relu\")(x)\n",
        "\n",
        "  x=Conv2D(filters,3,padding=\"same\")(x)\n",
        "  x=BatchNormalization()(x)\n",
        "  x=Activation(\"relu\")(x)\n",
        "\n",
        "  if pool == True:\n",
        "    p = MaxPool2D((2,2))(x)\n",
        "    return x,p\n",
        "  else:\n",
        "    return x\n",
        "\n"
      ],
      "metadata": {
        "id": "A9dFHmsOW6LK"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_unet(shape, num_class):\n",
        "  inputs=Input(shape)\n",
        "\n",
        "  #Encoder\n",
        "  x1,p1=conv_block(inputs, 16, pool=True)\n",
        "  x2,p2=conv_block(p1, 32,pool=True)\n",
        "  x3,p3=conv_block(p2, 48, pool=True)\n",
        "  x4,p4=conv_block(p3, 64, pool=True)\n",
        "\n",
        "  #Bridge\n",
        "  b1= conv_block(p4, 128, pool=False)\n",
        "\n",
        "  #Decoder\n",
        "  u1=UpSampling2D((2,2), interpolation=\"bilinear\")(b1)\n",
        "  # print(u1.shape,x4.shape)\n",
        "  c1=Concatenate()([u1, x4])\n",
        "  x5=conv_block(c1, 64, pool=False)\n",
        "\n",
        "  u2=UpSampling2D((2,2), interpolation=\"bilinear\")(x5)\n",
        "  # print(u2.shape,x3.shape)\n",
        "  c2=Concatenate()([u2, x3])\n",
        "  x6=conv_block(c2, 48, pool=False)\n",
        "\n",
        "  u3=UpSampling2D((2,2), interpolation=\"bilinear\")(x6)\n",
        "  # print(u3.shape,x2.shape)\n",
        "  c3=Concatenate()([u3, x2])\n",
        "  x7=conv_block(c3, 32, pool=False)\n",
        "\n",
        "  u4=UpSampling2D((2,2), interpolation=\"bilinear\")(x7)\n",
        "  # print(u4.shape,x1.shape)\n",
        "  c4=Concatenate()([u4, x1])\n",
        "  x8=conv_block(c4, 16, pool=False)\n",
        "\n",
        "  #Output\n",
        "  output=Conv2D(num_class, 3, padding=\"same\", activation=\"softmax\")(x8)\n",
        "\n",
        "  return Model(inputs, output)"
      ],
      "metadata": {
        "id": "_ACqF_GNXpSz"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model= build_unet((256,256,3),1)\n",
        "# model.summary()"
      ],
      "metadata": {
        "id": "FSGsCHEDZLCS"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PeKjZ4HZZT2U"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cTEtgqiJoShk"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Bvho2Vq1oSmD"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Seeding \n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n"
      ],
      "metadata": {
        "id": "CZ16NkjQoSqT"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dataset\n",
        "(train_x,train_y), (val_x,val_y), (test_x,test_y) = load_data(test_df_path,train_df_path)\n",
        "print(f\"Dataset: Train: {len(train_x)} -Valid: {len(val_x)} -Test: {len(test_x)}\")\n",
        "print(f\"Masks: Train: {len(train_y)} -Valid: {len(val_y)} -Test:{len(test_y)}\")\n"
      ],
      "metadata": {
        "id": "cxsb66yYojTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LBJ9big9wYom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter\n",
        "\n",
        "shape=(256,256,3)\n",
        "num_class=2\n",
        "lr=1e-2\n",
        "batch_size= 8\n",
        "epochs=10\n",
        "\n",
        "\n",
        "# shape = (256, 256, 3)\n",
        "# num_classes = 2\n",
        "# lr = 1e-4\n",
        "# batch_size = 8\n",
        "# epochs = 10"
      ],
      "metadata": {
        "id": "A8mkr4KbotL2"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model\n",
        "model = build_unet(shape,num_class)\n",
        "model.compile(loss=tf.keras.losses.CategoricalCrossentropy,\n",
        "              optimizer=tf.keras.optimizers.Adam(lr))\n",
        "train_dataset=tf_dataset(train_x,train_y,batch=batch_size)\n",
        "val_dataset=tf_dataset(val_x,val_y, batch=batch_size)\n",
        "\n",
        "train_steps=len(train_x)//batch_size\n",
        "val_steps=len(val_x)//batch_size\n",
        "\n",
        "\n",
        "\n",
        "model = build_unet(shape, num_classes)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(lr))\n",
        "\n",
        "train_dataset=tf_dataset(train_x,train_y,batch=batch_size)\n",
        "valid_dataset=tf_dataset(val_x,val_y, batch=batch_size)\n",
        "\n",
        "train_steps = len(train_x)//batch_size\n",
        "valid_steps = len(valid_x)//batch_size"
      ],
      "metadata": {
        "id": "jWNJcScco7XS"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint('model.h5', verbose=1, save_best_model=True),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", patience=3, factor=0.1, verbose=1, min_lr=1e-7),\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1)\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "ddMsEwGXt38a"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.fit(train_dataset,\n",
        "#           steps_per_epoch = train_steps,\n",
        "#           # validation_split=0.2,\n",
        "#           validation_data = val_dataset,\n",
        "#           # validataion_steps = val_steps,\n",
        "#           epochs =epochs,\n",
        "#           callbacks= callbacks\n",
        "#           )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "VuztYOf9wU-9",
        "outputId": "9ff0305f-3207-49fd-842e-5482a859e5d7"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-4c6974f177ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0;31m# validataion_steps = val_steps,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m           )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 919, in compute_loss\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 143, in __call__\n        losses, sample_weight, reduction=self._get_reduction())\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/losses_utils.py\", line 309, in compute_weighted_loss\n        losses = tf.convert_to_tensor(losses)\n\n    TypeError: Failed to convert elements of <keras.losses.CategoricalCrossentropy object at 0x7fe051cba550> to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " \"\"\" Seeding \"\"\"\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\"\"\" Dataset \"\"\"\n",
        "path = \"oxford-iiit-pet/\"\n",
        "(train_x,train_y), (valid_x,valid_y), (test_x,test_y) = load_data(test_df_path,train_df_path)\n",
        "print(f\"Dataset: Train: {len(train_x)} - Valid: {len(valid_x)} - Test: {len(test_x)}\")\n",
        "\n",
        "\"\"\" Hyperparameters \"\"\"\n",
        "shape = (256, 256, 3)\n",
        "num_classes = 2\n",
        "lr = 1e-4\n",
        "batch_size = 8\n",
        "epochs = 10\n",
        "\n",
        "\"\"\" Model \"\"\"\n",
        "model = build_unet(shape, num_classes)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(lr))\n",
        "\n",
        "train_dataset=tf_dataset(train_x,train_y,batch=batch_size)\n",
        "valid_dataset=tf_dataset(val_x,val_y, batch=batch_size)\n",
        "\n",
        "train_steps = len(train_x)//batch_size\n",
        "valid_steps = len(valid_x)//batch_size\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(\"model.h5\", verbose=1, save_best_model=True),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", patience=3, factor=0.1, verbose=1, min_lr=1e-6),\n",
        "    EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1)\n",
        "]\n",
        "\n",
        "model.fit(train_dataset,\n",
        "    steps_per_epoch=train_steps,\n",
        "    validation_data=valid_dataset,\n",
        "    validation_steps=valid_steps,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "g5Jobmfe0E6u",
        "outputId": "7c9f5588-3cf8-4730-8632-92bce362b9b5"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/CBIS-DDSM/Unet_mask/mass/Image_mask_train.csv\n",
            "/content/drive/MyDrive/CBIS-DDSM/Unet_mask/mass/Image_mask_test.csv\n",
            "Dataset: Train: 916 - Valid: 230 - Test: 327\n",
            "Epoch 1/10\n",
            " 31/114 [=======>......................] - ETA: 11:54 - loss: 0.6885"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-77b09e3a738e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m    \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m    \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m    \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5GTE_wJy3IUC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}